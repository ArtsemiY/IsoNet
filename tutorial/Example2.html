<!DOCTYPE html>
<html>
<head>
<title>Example2.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h2 id="a-step-by-step-examples">A step by step examples</h2>
<p>This example processes tomogram containing HIV virus particles through <strong>IsoNet</strong>.</p>
<h3 id="prepare-tomograms-and-star-file">Prepare tomograms and STAR file</h3>
<p>First, create a folder for your project. In this folder, create
subfolder (in this case subfolder name is tomoset) and move all tomogram
(with suffix .mrc or .rec) to the subfolder.</p>
<pre class="hljs"><code><div>mkdir tomoset
mv TS*.rec tomoset/
</div></code></pre>
<p>Then run the following command in your project folder to generate a
tomogram.star file (in this example, the name of tomogram.star file is
hiv_tomo.star)</p>
<pre class="hljs"><code><div>isonet.py prepare_star tomoset --output_star hiv_tomo.star --pixel_size 10.8
</div></code></pre>
<p>If you are not using GUI, please use your favorite text editor, such as
vi or gedit, to open the <strong>hiv_tomo.star</strong>, and enter one defocus value
for each tomogram in the fourth column. This value should be the approximate
defocus value calculated for the 0-degree tilt images in angstrom. After
editing, your star file should look as follows. Note, this value is
only for CTF deconvolution, if you want to skip CTF deconvolution step,
leave this column as default 0.</p>
<pre class="hljs"><code><div>data_

loop_
_rlnIndex #1
_rlnMicrographName #2
_rlnPixelSize #3
_rlnDefocus #4
_rlnNumberSubtomo #5
1       tomoset/TS01-wbp.rec    10.800000       38838.257812    100
2       tomoset/TS43-wbp.rec    10.800000       25292.275391    100
3       tomoset/TS45-wbp.rec    10.800000       30169.785156    100
</div></code></pre>
<h2 id="ctf-deconvolve">CTF Deconvolve</h2>
<p>This step not only reduces the CTF artifact but also enhances the low
resolution signal making training easier. This step is optional and can
not be performed for tomograms acquired with phase plate.</p>
<p>Type the following command in the terminal in your project folder. It
will generate deconvolved tomograms in <strong>hiv_deconv</strong> folder.</p>
<pre class="hljs"><code><div>isonet.py deconv hiv_tomo.star --snrfalloff 0.7 --deconv_folder hiv_deconv
</div></code></pre>
<p>If the command runs successfully, you will get the following terminal
output:</p>
<pre class="hljs"><code><div>######Isonet starts ctf deconvolve######

tomoset/TS01-wbp.rec angpix: 10.8 defocus 3.8838257812 snrfalloff 0.7 deconvstrength 1.0
deconvolved map is saved as  hiv_deconv/TS01-wbp.rec
time consumed:  14.191490888595581

tomoset/TS43-wbp.rec angpix: 10.8 defocus 2.5292275391 snrfalloff 0.7 deconvstrength 1.0
deconvolved map is saved as  hiv_deconv/TS01-wbp.rec
time consumed:  8.547893047332764

tomoset/TS45-wbp.rec angpix: 10.8 defocus 3.0169785156 snrfalloff 0.7 deconvstrength 1.0
deconvolved map is saved as  hiv_deconv/TS01-wbp.rec
time consumed:  8.76533579826355

######Isonet done ctf deconvolve######
</div></code></pre>
<h2 id="generate-mask">Generate Mask</h2>
<p>To exclude the areas that are devoid of sample, we apply a binary sampling
mask to each tomogram. This step is optional but will improve the
efficiency of the network training.</p>
<p>By running the following command, 3D mask volumes for each tomogram will be
generated and stored in the <strong>hiv_mask</strong> folder. Default parameters will
give you a good enough mask.</p>
<pre class="hljs"><code><div>isonet.py make_mask hiv_tomo.star --mask_folder hiv_mask --density_percentage 50 --std_percentage 50
</div></code></pre>
<p>If this command works properly, you will find the mask file, when opened
with your favorite mrc image viewer such as 3dmod, covers the areas of
your sample of interest. Both this step and CTF deconvolve step will
modify your tomogram star file (<strong>hiv_tomo.star</strong>):</p>
<pre class="hljs"><code><div>data_

loop_
_rlnIndex #1
_rlnMicrographName #2
_rlnPixelSize #3
_rlnDefocus #4
_rlnNumberSubtomo #5
_rlnSnrFalloff #6
_rlnDeconvStrength #7
_rlnDeconvTomoName #8
_rlnMaskDensityPercentage #9
_rlnMaskStdPercentage #10
_rlnMaskName #11
1       tomoset/TS01-wbp.rec    10.800000       38838.257812    100     0.700000        1.000000        hiv_deconv/TS01-wbp.rec         50.000000    50.000000       hiv_mask/TS01-wbp_mask.mrc
2       tomoset/TS43-wbp.rec    10.800000       25292.275391    100     0.700000        1.000000        hiv_deconv/TS43-wbp.rec         50.000000    50.000000       hiv_mask/TS43-wbp_mask.mrc
3       tomoset/TS45-wbp.rec    10.800000       30169.785156    100     0.700000        1.000000        hiv_deconv/TS45-wbp.rec         50.000000    50.000000       hiv_mask/TS45-wbp_mask.mrc
</div></code></pre>
<h2 id="extract-subtomograms">Extract Subtomograms</h2>
<p>This step extracts small 3D volumes (here we also call subtomograms)
randomly from previously described tomograms or deconvoluted tomograms. If
you provide a mask in your tomogram star file, the center of the
subtomograms is inside the mask areas. The number of subtomograms to be
extracted in each tomogram is defined in the <strong>_rlnNumberSubtomo</strong>
column in your tomogram star file. You can edit those as your desired
value. Usually, total of 300 subtomograms are sufficient for network
training.</p>
<p>The following command takes your tomogram star file as input and
Generates subtomograms in a folder named subtomo as well as a file named
subtomo.star</p>
<pre class="hljs"><code><div>isonet.py extract hiv_tomo.star
</div></code></pre>
<p>The subtomo.star contains information for your subtomograms.
<strong>_rlnCropSize</strong> is the size of subtomograms, and <strong>_rlnCubeSize</strong> is the
size actually used for network training, You can specify these values in
the <em>extract</em> command.</p>
<pre><code>data_

loop_
_rlnSubtomoIndex #1
_rlnImageName #2
_rlnCubeSize #3
_rlnCropSize #4
_rlnPixelSize #5
1       subtomo/TS01-wbp_000000.mrc     64      96      10.800000
2       subtomo/TS01-wbp_000001.mrc     64      96      10.800000
3       subtomo/TS01-wbp_000002.mrc     64      96      10.800000
4       subtomo/TS01-wbp_000003.mrc     64      96      10.800000
5       subtomo/TS01-wbp_000004.mrc     64      96      10.800000
6       subtomo/TS01-wbp_000005.mrc     64      96      10.800000
7       subtomo/TS01-wbp_000006.mrc     64      96      10.800000
8       subtomo/TS01-wbp_000007.mrc     64      96      10.800000
9       subtomo/TS01-wbp_000008.mrc     64      96      10.800000
10      subtomo/TS01-wbp_000009.mrc     64      96      10.800000
11      subtomo/TS01-wbp_000010.mrc     64      96      10.800000
12      subtomo/TS01-wbp_000011.mrc     64      96      10.800000
</code></pre>
<h2 id="refine">Refine</h2>
<p>The extracted sub-tomograms and subtomo star file are used as input in
this refine step, which iteratively trains networks that fill the
missing wedge information (and reduce noise). The output is defined by
<strong>the result_dir</strong> parameter, whose default value is &quot;results&quot;. In this
folder, you will find all the subtomograms in each iteration as well as
the network model files with the extension of h5, if this command runs
successfully.</p>
<p>it will take about 10 hours for four Nvidia 1080Ti to finish the refine
step with the following command:</p>
<pre class="hljs"><code><div>isonet.py refine subtomo.star --gpuID 0,1,2,3 --iterations 30 --noise_start_iter 10,15,20,25 --noise_level 0.05,0.1,0.15,0.2 
</div></code></pre>
<p>Once you execute the refine step, you will get the command line output
as follows:</p>
<pre class="hljs"><code><div>######Isonet starts refining######

06-11 22:00:55, INFO     Done preperation for the first iteration!
06-11 22:00:55, INFO     Start Iteration1!
06-11 22:00:59, INFO     Noise Level:0.0
06-11 22:01:36, INFO     Done preparing subtomograms!
06-11 22:01:36, INFO     Start training!
06-11 22:01:38, INFO     Loaded model from disk
06-11 22:01:38, INFO     begin fitting
Epoch 1/10
112/112 [==============================] - 106s 944ms/step - loss: 0.1597 - mse: 0.0726 - mae: 0.1597 - val_loss: 0.1575 - val_mse: 0.0711 - val_mae: 0.1575
Epoch 2/10
112/112 [==============================] - 101s 897ms/step - loss: 0.1543 - mse: 0.0591 - mae: 0.1543 - val_loss: 0.1617 - val_mse: 0.0726 - val_mae: 0.1617
Epoch 3/10
112/112 [==============================] - 101s 904ms/step - loss: 0.1489 - mse: 0.0513 - mae: 0.1489 - val_loss: 0.1535 - val_mse: 0.0616 - val_mae: 0.1535
Epoch 4/10
112/112 [==============================] - 101s 903ms/step - loss: 0.1486 - mse: 0.0489 - mae: 0.1486 - val_loss: 0.1583 - val_mse: 0.0687 - val_mae: 0.1583
Epoch 5/10
112/112 [==============================] - 101s 905ms/step - loss: 0.1467 - mse: 0.0458 - mae: 0.1467 - val_loss: 0.1482 - val_mse: 0.0478 - val_mae: 0.1482
Epoch 6/10
112/112 [==============================] - 102s 906ms/step - loss: 0.1449 - mse: 0.0442 - mae: 0.1449 - val_loss: 0.1472 - val_mse: 0.0487 - val_mae: 0.1472
Epoch 7/10
112/112 [==============================] - 102s 906ms/step - loss: 0.1430 - mse: 0.0409 - mae: 0.1430 - val_loss: 0.1410 - val_mse: 0.0411 - val_mae: 0.1410
Epoch 8/10
112/112 [==============================] - 102s 908ms/step - loss: 0.1437 - mse: 0.0408 - mae: 0.1437 - val_loss: 0.1427 - val_mse: 0.0437 - val_mae: 0.1427
Epoch 9/10
112/112 [==============================] - 102s 909ms/step - loss: 0.1413 - mse: 0.0393 - mae: 0.1413 - val_loss: 0.1415 - val_mse: 0.0387 - val_mae: 0.1415
Epoch 10/10
112/112 [==============================] - 102s 910ms/step - loss: 0.1406 - mse: 0.0383 - mae: 0.1406 - val_loss: 0.1430 - val_mse: 0.0399 - val_mae: 0.1430
06-11 22:21:04, INFO     Done training!
06-11 22:21:04, INFO     Start predicting subtomograms!
06-11 22:22:53, INFO     Done predicting subtomograms!
06-11 22:22:53, INFO     Done Iteration1!
06-11 22:22:53, INFO     Start Iteration2!
</div></code></pre>
<p>You can also continue from the pretrained model for this dataset
provided in the link. The following command will use the pre-trained
network model as the model of 1st iteration, then predict subtomos and
train networks starting from this model.:</p>
<pre class="hljs"><code><div>isonet.py refine subtomo.star --pretrained_model ./pretrained_model.h5  --gpuID 0,1,2,3 
</div></code></pre>
<p>Another option is to continues from previous runs, with
<strong>continue_from</strong> command. This option allows reading the parameter from
previous iteration in '.json' file and continuing from that. For example:</p>
<pre class="hljs"><code><div>isonet.py refine subtomo.star --continue_from results/refine_iter20.json  --gpuID 0,1,2,3 
</div></code></pre>
<h2 id="predict">Predict</h2>
<p>During the refinement step, the network models are saved in <strong>result_dir</strong>
folder. You can select one and apply it to your entire tomograms in the
tomogram star file. For example:</p>
<pre><code>isonet.py predict tomograms.star ./results/model_iter40.h5 --gpuID 0,1,2,3
</code></pre>
<p>This process may take a few minutes to predict all tomograms in the
tutorial dataset. You can also use <strong>tomo_idx</strong> to tell the program
which tomogram(s) you want to predict.</p>
<p>Now, We now the missing wedge corrected tomograms in the corrected_tomos
folder.</p>

</body>
</html>
