{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "This command will train a 3D U-net network based on users' input then, after succesful training, a model file will be stored in the result folder which serves for the MWR prediction. \n",
    "For detail instruction, please run the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Showing help with the command 'mwr_cli.py train -- --help'.\n",
      "\n",
      "\u001b[1mNAME\u001b[0m\n",
      "    mwr_cli.py train - Preprocess tomogram and train u-net model on generated subtomos\n",
      "\n",
      "\u001b[1mSYNOPSIS\u001b[0m\n",
      "    mwr_cli.py train \u001b[4mINPUT_DIR\u001b[0m <flags>\n",
      "\n",
      "\u001b[1mDESCRIPTION\u001b[0m\n",
      "    Preprocess tomogram and train u-net model on generated subtomos\n",
      "\n",
      "\u001b[1mPOSITIONAL ARGUMENTS\u001b[0m\n",
      "    \u001b[1m\u001b[4mINPUT_DIR\u001b[0m\u001b[0m\n",
      "        path to tomogram from which subtomos are sampled; format: .mwr or .rec\n",
      "\n",
      "\u001b[1mFLAGS\u001b[0m\n",
      "    --gpuID=\u001b[4mGPUID\u001b[0m\n",
      "        (0,1,2,3) The gpuID to used during the training. e.g 0,1,2,3.\n",
      "    --mask=\u001b[4mMASK\u001b[0m\n",
      "        (None) if sample subtomos with a mask to exclude background region. (None) the path to mask file or None\n",
      "    --noise_folder=\u001b[4mNOISE_FOLDER\u001b[0m\n",
      "        Add noise during training, Set None to disable noise reduction.\n",
      "    --iterations=\u001b[4mITERATIONS\u001b[0m\n",
      "        (50) Number of training iterations.\n",
      "    --datas_are_subtomos=\u001b[4mDATAS_ARE_SUBTOMOS\u001b[0m\n",
      "        (False) Is your trainin data subtomograms?\n",
      "    --subtomo_dir=\u001b[4mSUBTOMO_DIR\u001b[0m\n",
      "        (subtomo) The folder where the input subtomograms at.\n",
      "    --data_folder=\u001b[4mDATA_FOLDER\u001b[0m\n",
      "        (data)Temperary folder to save the generated data used for training.\n",
      "    --pretrained_model=\u001b[4mPRETRAINED_MODEL\u001b[0m\n",
      "    --log_level=\u001b[4mLOG_LEVEL\u001b[0m\n",
      "        (debug) logging level\n",
      "\n",
      "        ************************continue training settings************************\n",
      "    --continue_training=\u001b[4mCONTINUE_TRAINING\u001b[0m\n",
      "        (False) Continus previous training? When continue, the architecture of network can not be changed.\n",
      "    --continue_iter=\u001b[4mCONTINUE_ITER\u001b[0m\n",
      "        (0) Which iteration you want to start from?\n",
      "\n",
      "        ************************noise settings************************\n",
      "    --noise_level=\u001b[4mNOISE_LEVEL\u001b[0m\n",
      "        Level of noise STD(added noise)/STD(data).\n",
      "    --noise_start_iter=\u001b[4mNOISE_START_ITER\u001b[0m\n",
      "        Iteration that start to add trainning noise.\n",
      "    --noise_pause=\u001b[4mNOISE_PAUSE\u001b[0m\n",
      "        Iters trainning noise remain at one level.\n",
      "\n",
      "        ************************preprocessing settings************************\n",
      "    --cube_sidelen=\u001b[4mCUBE_SIDELEN\u001b[0m\n",
      "        Size of training cubes, this size should be divisible by 2^unet_depth.\n",
      "    --cropsize=\u001b[4mCROPSIZE\u001b[0m\n",
      "        Size of cubes to impose missing wedge. Should be same or larger than size of cubes.\n",
      "    --ncube=\u001b[4mNCUBE\u001b[0m\n",
      "        Number of cubes generated for each (sub)tomos. Because each (sub)tomo rotates 16 times, the actual number of cubes for trainings should be ncube*16.\n",
      "    --preprocessing_ncpus=\u001b[4mPREPROCESSING_NCPUS\u001b[0m\n",
      "        (16) Number of cpu for preprocessing.\n",
      "\n",
      "        ************************training settings************************\n",
      "    --epochs=\u001b[4mEPOCHS\u001b[0m\n",
      "        Number of epoch for each iteraction.\n",
      "    --batch_size=\u001b[4mBATCH_SIZE\u001b[0m\n",
      "        Size of the minibatch.\n",
      "    --steps_per_epoch=\u001b[4mSTEPS_PER_EPOCH\u001b[0m\n",
      "        Step per epoch. A good estimation of this value is (sub)tomos * ncube * 16 / batch_size *0.9.\")\n",
      "\n",
      "        ************************predict settings************************\n",
      "    --predict_cropsize=\u001b[4mPREDICT_CROPSIZE\u001b[0m\n",
      "        Predict cubesize.\n",
      "    --predict_batch_size=\u001b[4mPREDICT_BATCH_SIZE\u001b[0m\n",
      "    --drop_out=\u001b[4mDROP_OUT\u001b[0m\n",
      "        Drop out rate to reduce overfitting.\n",
      "    --convs_per_depth=\u001b[4mCONVS_PER_DEPTH\u001b[0m\n",
      "        Number of convolution layer for each depth.\n",
      "    --kernel=\u001b[4mKERNEL\u001b[0m\n",
      "        Kernel for convolution\n",
      "    --unet_depth=\u001b[4mUNET_DEPTH\u001b[0m\n",
      "        Number of convolution layer for each depth.\n",
      "    --batch_normalization=\u001b[4mBATCH_NORMALIZATION\u001b[0m\n",
      "        Sometimes batch normalization may induce artifacts for extreme pixels in the first several iterations. Those could be restored in further iterations.\n",
      "    --normalize_percentile=\u001b[4mNORMALIZE_PERCENTILE\u001b[0m\n",
      "        Normalize the 5 percent and 95 percent pixel intensity to 0 and 1 respectively. If this is set to False, normalize the input to 0 mean and 1 standard dievation.\n",
      "\n",
      "\u001b[1mNOTES\u001b[0m\n",
      "    You can also use flags syntax for POSITIONAL ARGUMENTS\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mwr_cli.py train -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters tuning\n",
    "The following parameters need to be tuned with respect to user's data and hardware.\n",
    "\n",
    "iteration parameter defines the number of iterations that will be used to correct missing wedge. In each iteration, three steps will be performed: preprocessing, training, and prediction.\n",
    " \n",
    "In preprocessing, the sub-tomograms with size **cube_size** are extracted randomly from the tomograms. If masks are applied, the center of the sub-tomograms should be within the masked areas. Those sub-tomograms are then rotated and cropped to the size serve as the input. Those same sub-tomograms are rotated, added missing wedge and then cropped to the same size to serve as the output of the network. Usually the **crop_size** is 1.5 time larger than the **cube_size**. By default, each sub-tomograms are rotated 16 times making 16 data pairs. Those generated input-output data pairs store in the **data** folder and will be used in the following training. The preprocessing step can only be performed with cpu, which specified in the parameter **preprocessing_ncpus**.\n",
    " \n",
    "The training step used GPU to train the neural network. The ID of GPU is can be assigned in **gpuID**. The training step is divided into several **epochs**. Each epoch will traverse through the data set. The data pairs are grouped into batches to feed into each epoch. It is recommended that the **batchsize** times the **step_per_epoch** approximately equals the number of the data pairs. If you are using multiple GPUs, the **batchsize** should be divisible to the number of GPU. The trained neural networks are saved in the **result_dir** folder named model_iterxx.h5. \n",
    " \n",
    "The prediction step performs the missing wedge correction of each sub-tomograms. Similar to the training, the sub-tomograms are grouped in to batches **predict_batch_size**.  The predicted sub-tomograms will be used for processing for the subsequent iterations.\n",
    " \n",
    "## that’s it\n",
    "The resulting **model_iterxx.h5** is the network to be used in the next module: Missing wedge correction of the entire tomogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
