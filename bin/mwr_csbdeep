#!/usr/bin/env python3

from mwr.util import readMrcNumpy,readHeader,PercentileNormalizer
from mwr.simulation import TwoDPsf,TrDPsf
from mwr.util.generate import DataPairs
import numpy as np
from tifffile import imread,imsave
from mwr.models import unet
from scipy.ndimage.interpolation import rotate
from csbdeep.models import Config,CARE
import os


def mrcRead(mrc):
    data=readMrcNumpy(mrc)
    header=readHeader(mrc)
    return data,header

def get_patches(orig_data,outName='train_and_test_data.npz',npathcesper=100,patches_sidelen=128,rotate=False,prefilter=None \
    ,noisefilter=False,type=None):

    #imgpre.imsave(filename+'_convoluted',convoluted)

    pair=DataPairs()
    pair.set_dataY(orig_data)
    pair.set_dataX(orig_data)
    if prefilter!=None:
        pair.prefilter(prefilter[0],prefilter[1])
    if rotate==True :
        pair.rotate()
    sp=pair.get_dataX().shape
    twoD_missingwedge=TwoDPsf(sp[1],sp[2])
    pair.set_dataX(twoD_missingwedge.apply(pair.get_dataX()))
    pair.create_patches(patches_sidelen,npathcesper,withFilter=filter)
    train_data,test_data=pair.create_training_data2D()
    print ('train_data.shape:',train_data[0].shape)
    np.savez(outName,train_data=train_data,test_data=test_data)
def get_cubes(orig_data,outName,ncube=1000,cube_sidelen=64):
    pair = DataPairs()
    pair.set_dataX(orig_data)
    pair.set_dataY(orig_data)
    pair.create_cubes(nCubesPerImg=ncube,cubeSideLen=cube_sidelen)
    threeD_missingwedge=TrDPsf(cube_sidelen)
    print('cubes.shape',pair.cubesX.shape)
    pair.cubesX=threeD_missingwedge.apply(pair.cubesX)
    train_data, test_data=pair.create_training_data3D()
    print ('train_data.shape:', train_data[0].shape)
    np.savez(outName, train_data=train_data, test_data=test_data)

def get_cubes_wholeconv(orig_data,outName,ncube=1000,cube_sidelen=64):
    threeD_missingwedge=TrDPsf(cube_sidelen)
    print('convoluting')
    conved = threeD_missingwedge.apply(orig_data)
    print('convoluted')
    imsave('GTconved3D.tif',conved)
    pair = DataPairs()
    pair.set_dataX(conved)
    pair.set_dataY(orig_data)
    pair.create_cubes(nCubesPerImg=ncube,cubeSideLen=cube_sidelen)
    train_data, test_data=pair.create_training_data3D()
    np.savez(outName, train_data=train_data, test_data=test_data)

def train_data(fileName, outFile, n_gpus):

    data = np.load(fileName)
    Normalizer = PercentileNormalizer()
    (x,y,x_val,y_val) = (data['train_data'][0],data['train_data'][1],data['test_data'][0],data['test_data'][1])
    x = Normalizer.before(x,'ZYXC')
    y = Normalizer.before(y,'ZYXC')
    x_val = Normalizer.before(x_val,'ZYXC')
    y_val = Normalizer.before(y_val,'ZYXC')
    config = Config(axes='YXC',n_channel_in=1,n_channel_out=1,n_dim=2,probabilistic=True)
    model = CARE(config,'my_model',basedir='/home/heng/mwr/test_data/run_csbdeep')
    history = model.train(x,y,(x_val,y_val))

def train_data3D(fileName, outFile,epochs=40,batch_size=32,steps_per_epoch=28, n_gpus=2):
    data = np.load(fileName)
    
    #Normalizer = PercentileNormalizer()
    (x,y,x_val,y_val) = (data['train_data'][0],data['train_data'][1],data['test_data'][0],data['test_data'][1])
    #(x,y,x_val,y_val)=map(Normalizer.before,((x,'ZYXC'),(y,'ZYXC'),(x_val,'ZYXC'),(y_val,'ZYXC'))
    '''    
    x = Normalizer.before(x,'ZYXC')
    y = Normalizer.before(y,'ZYXC')
    x_val = Normalizer.before(x_val,'ZYXC')
    y_val = Normalizer.before(y_val,'ZYXC')
    print('x shape',x.shape)
    '''
    unet.train3D(x,y,(x_val,y_val),outFile,epochs=epochs,steps_per_epoch=steps_per_epoch,batch_size=batch_size,n_gpus=n_gpus)




if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser(description='Process some integers.')
    parser.add_argument('file', type=str, help='Your mrc file')
    parser.add_argument('--weight', type=str, default='weights_last.h5' ,help='Weight file to save')
    parser.add_argument('--data', type=str, default='train_and_test_data' ,help='Data file to save')
    parser.add_argument('--type', type=str, default='rec', help='type of data .mrc or .tif')
    parser.add_argument('--gpus', type=int, default=2, help='number of gpu fro training')
    parser.add_argument('--dim', type=str, default='2D', help='training 2D or 3D')
    args = parser.parse_args()

    #os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"
    #os.environ["CUDA_VISIBLE_DEVICES"]="1,2"  # specify which GPU(s) to be used

    if args.type=='rec':
        data,header=mrcRead(args.file)
    else:
        data=imread(args.file)
    if args.dim=='2D':
        num_image=data.shape[0]
        data=data[int(0.1*num_image):int(0.9*num_image)]
        #get_patches(data,outName=args.data+'2D.npz',npathcesper=40,patches_sidelen=64,rotate=True,prefilter=None \
        #,noisefilter=False,type=None)
        train_data(args.data, args.weight, n_gpus=args.gpus)
    else :
        data_rotated = rotate(data,angle=90,axes=(0,2))
        num_image=data_rotated.shape[2]
        data_rotated=data_rotated[:,:,int(0.1*num_image):int(0.9*num_image)]
        print('data_rotated.shape:',data_rotated.shape)
        imsave('GT_xzy.tif',data_rotated)
        get_cubes_wholeconv(data_rotated,outName=args.data+'3D.npz',ncube=1024,cube_sidelen=64)
        print('cubes got')
        train_data3D(args.data+'3D.npz',args.weight,epochs=30,n_gpus=args.gpus,batch_size=64,steps_per_epoch=None)
    

    
